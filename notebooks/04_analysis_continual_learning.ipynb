{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98e2e1df",
   "metadata": {},
   "source": [
    "# Continual Learning Analysis - Dataset Agnostic\n",
    "\n",
    "Compare baseline vs. PSP models on arbitrary datasets and task transforms.\n",
    "\n",
    "Features:\n",
    "- Works with any torchvision dataset (MNIST, CIFAR-10, FashionMNIST, etc.)\n",
    "- Supports multiple task transforms (Permutation, Rotation, Class-Incremental)\n",
    "- Trains both baseline and context-aware models\n",
    "- Visualizes accuracy curves and hidden representations via PCA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204db6c1",
   "metadata": {},
   "source": [
    "## Setup: Path Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e75801c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added to sys.path: /Users/lorenzleisner/Desktop/CogSci/Master/WI_SE_25/hands-on-neuroai/src\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "repo_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "src_path = os.path.join(repo_root, \"src\")\n",
    "\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "\n",
    "print(\"Added to sys.path:\", src_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59eeea0e",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81e45e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from hands_on_neuroai.data.datasets import (\n",
    "    DatasetConfig, get_image_shape, get_num_classes,\n",
    "    build_task_datasets, build_dataloaders,\n",
    "    PermutePixels, Rotate, ComposeTaskTransforms\n",
    ")\n",
    "from hands_on_neuroai.training.continual_learning import (\n",
    "    train_model_on_continual_learning_tasks\n",
    ")\n",
    "from hands_on_neuroai.training.metrics import collect_hidden_activations\n",
    "from hands_on_neuroai.models.factory import build_model_for_continual_learning\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050d95fe",
   "metadata": {},
   "source": [
    "## Configuration: Dataset, Tasks, and Model Parameters\n",
    "\n",
    "Customize these settings to experiment with different datasets, task transforms, and models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f57c29a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: mnist\n",
      "Task Transform: permutation\n",
      "Num Tasks: 5\n",
      "Model Context: binary\n",
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# ============ Dataset & Data Configuration ============\n",
    "dataset_name = \"mnist\"  # Options: \"mnist\", \"cifar10\", \"cifar100\", \"fashionmnist\"\n",
    "data_root = \"data\"\n",
    "\n",
    "# ============ Task Configuration ============\n",
    "num_tasks = 5\n",
    "task_transform_type = \"permutation\"  # Options: \"permutation\", \"rotation\", \"class_incremental\"\n",
    "\n",
    "# For permutation and rotation tasks\n",
    "steps_per_task = 100\n",
    "batch_size = 128\n",
    "\n",
    "# ============ Model Configuration ============\n",
    "hidden_dim = 128\n",
    "context_type = \"binary\"  # Options: \"none\", \"binary\", \"complex\", \"rotation\"\n",
    "\n",
    "# ============ Training Configuration ============\n",
    "eval_interval = steps_per_task // 5\n",
    "learning_rate = 1e-3\n",
    "base_seed = 0\n",
    "\n",
    "print(f\"Dataset: {dataset_name}\")\n",
    "print(f\"Task Transform: {task_transform_type}\")\n",
    "print(f\"Num Tasks: {num_tasks}\")\n",
    "print(f\"Model Context: {context_type}\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e20f26d",
   "metadata": {},
   "source": [
    "## Step 1: Build Data Loaders\n",
    "\n",
    "Create data loaders with the specified dataset and task transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f0bcda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:09<00:00, 1043936.12it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 217083.22it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:01<00:00, 1139267.68it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 1316917.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Train loaders: 5, Test loaders: 5\n",
      "Task transforms: permutation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create dataset config\n",
    "config = DatasetConfig(root=data_root, download=False)\n",
    "\n",
    "# Create task transforms based on task_transform_type\n",
    "if task_transform_type == \"permutation\":\n",
    "    task_transforms = [\n",
    "        PermutePixels(seed=base_seed + i) \n",
    "        for i in range(num_tasks)\n",
    "    ]\n",
    "elif task_transform_type == \"rotation\":\n",
    "    # Rotation angles from 0 to 180 degrees spread across tasks\n",
    "    angles = [int(180 * i / (num_tasks - 1)) for i in range(num_tasks)]\n",
    "    task_transforms = [Rotate(degrees=angles[i]) for i in range(num_tasks)]\n",
    "elif task_transform_type == \"class_incremental\":\n",
    "    # For class-incremental, we use a special builder\n",
    "    from hands_on_neuroai.data.datasets import build_class_incremental_tasks\n",
    "    input_dim, _ = get_image_shape(dataset_name)\n",
    "    output_dim = get_num_classes(dataset_name)\n",
    "    classes_per_task = output_dim // num_tasks\n",
    "    \n",
    "    train_dsets, test_dsets = build_class_incremental_tasks(\n",
    "        dataset_name=dataset_name,\n",
    "        config=config,\n",
    "        class_splits=[\n",
    "            list(range(i * classes_per_task, (i + 1) * classes_per_task))\n",
    "            for i in range(num_tasks)\n",
    "        ]\n",
    "    )\n",
    "    train_loaders = build_dataloaders(train_dsets, config, batch_size=batch_size, shuffle=True)\n",
    "    test_loaders = build_dataloaders(test_dsets, config, batch_size=batch_size, shuffle=False)\n",
    "    task_transforms = None  # Not needed for class-incremental\n",
    "else:\n",
    "    raise ValueError(f\"Unknown task_transform_type: {task_transform_type}\")\n",
    "\n",
    "# For permutation and rotation, build task datasets with transforms\n",
    "if task_transforms is not None:\n",
    "    train_dsets, test_dsets = build_task_datasets(\n",
    "        dataset_name=dataset_name,\n",
    "        config=config,\n",
    "        task_transforms=task_transforms\n",
    "    )\n",
    "    train_loaders = build_dataloaders(train_dsets, config, batch_size=batch_size, shuffle=True)\n",
    "    test_loaders = build_dataloaders(test_dsets, config, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Train loaders: {len(train_loaders)}, Test loaders: {len(test_loaders)}\")\n",
    "print(f\"Task transforms: {task_transform_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3647fad7",
   "metadata": {},
   "source": [
    "## Step 2: Initialize Baseline and Context-Aware Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "816ecdc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input dimension: 784, Output dimension: 10\n",
      "Baseline model created\n",
      "Context model (binary) created\n"
     ]
    }
   ],
   "source": [
    "# Get dataset-specific dimensions\n",
    "x, y = get_image_shape(dataset_name)\n",
    "input_dim = x * y\n",
    "output_dim = get_num_classes(dataset_name)\n",
    "\n",
    "print(f\"Input dimension: {input_dim}, Output dimension: {output_dim}\")\n",
    "\n",
    "# Build baseline model (no task awareness)\n",
    "baseline = build_model_for_continual_learning(\n",
    "    context_type=\"none\",\n",
    "    input_dim=input_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    output_dim=output_dim,\n",
    "    num_tasks=num_tasks,\n",
    "    base_seed=base_seed,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "# Build context-aware model (with specified context type)\n",
    "context_model = build_model_for_continual_learning(\n",
    "    context_type=context_type,\n",
    "    input_dim=input_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    output_dim=output_dim,\n",
    "    num_tasks=num_tasks,\n",
    "    base_seed=base_seed,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "print(f\"Baseline model created\")\n",
    "print(f\"Context model ({context_type}) created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1a8035",
   "metadata": {},
   "source": [
    "## Step 3: Train Models on Sequential Tasks\n",
    "\n",
    "This cell trains both models sequentially across all tasks, recording accuracy on task 0 throughout training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fb8ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training baseline model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "285d9874dedc49e08583e710894e00f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tasks:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "               ^^^^^^^^^^Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^    exitcode = _main(fd, parent_sentinel)\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "                  ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
      "^^^^^^^^\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lorenzleisner/Desktop/CogSci/Master/WI_SE_25/hands-on-neuroai/src/hands_on_neuroai/data/datasets.py\", line 9, in <module>\n",
      "^^\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lorenzleisner/Desktop/CogSci/Master/WI_SE_25/hands-on-neuroai/src/hands_on_neuroai/data/datasets.py\", line 9, in <module>\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^  File \"/Users/lorenzleisner/Desktop/CogSci/Master/WI_SE_25/hands-on-neuroai/src/hands_on_neuroai/data/datasets.py\", line 9, in <module>\n",
      "^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lorenzleisner/Desktop/CogSci/Master/WI_SE_25/hands-on-neuroai/src/hands_on_neuroai/data/datasets.py\", line 9, in <module>\n",
      "        from torchvision import datasets, transformsfrom torchvision import datasets, transforms\n",
      "\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/torchvision/__init__.py\", line 6, in <module>\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/torchvision/__init__.py\", line 6, in <module>\n",
      "    from torchvision import datasets, transforms\n",
      "    from torchvision import datasets, transforms\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/torchvision/__init__.py\", line 6, in <module>\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/torchvision/__init__.py\", line 6, in <module>\n",
      "        from torchvision import _meta_registrations, datasets, io, models, ops, transforms, utilsfrom torchvision import _meta_registrations, datasets, io, models, ops, transforms, utils\n",
      "\n",
      "    from torchvision import _meta_registrations, datasets, io, models, ops, transforms, utils\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/torchvision/models/__init__.py\", line 2, in <module>\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/torchvision/models/__init__.py\", line 2, in <module>\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/torchvision/models/__init__.py\", line 2, in <module>\n",
      "    from torchvision import _meta_registrations, datasets, io, models, ops, transforms, utils\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/torchvision/models/__init__.py\", line 2, in <module>\n",
      "    from .convnext import *\n",
      "    from .convnext import *    from .convnext import *\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/torchvision/models/convnext.py\", line 8, in <module>\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/torchvision/models/convnext.py\", line 8, in <module>\n",
      "    from .convnext import *\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/torchvision/models/convnext.py\", line 8, in <module>\n",
      "\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/torchvision/models/convnext.py\", line 8, in <module>\n",
      "    from ..ops.misc import Conv2dNormActivation, Permute        from ..ops.misc import Conv2dNormActivation, Permutefrom ..ops.misc import Conv2dNormActivation, Permute\n",
      "\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/torchvision/ops/__init__.py\", line 23, in <module>\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/torchvision/ops/__init__.py\", line 23, in <module>\n",
      "    from ..ops.misc import Conv2dNormActivation, Permute\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/torchvision/ops/__init__.py\", line 23, in <module>\n",
      "\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/torchvision/ops/__init__.py\", line 23, in <module>\n",
      "    from .poolers import MultiScaleRoIAlign\n",
      "    from .poolers import MultiScaleRoIAlign\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/torchvision/ops/poolers.py\", line 10, in <module>\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/torchvision/ops/poolers.py\", line 10, in <module>\n",
      "    from .poolers import MultiScaleRoIAlign\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/torchvision/ops/poolers.py\", line 10, in <module>\n",
      "    from .poolers import MultiScaleRoIAlign\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/torchvision/ops/poolers.py\", line 10, in <module>\n",
      "    from .roi_align import roi_align\n",
      "    from .roi_align import roi_align\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/torchvision/ops/roi_align.py\", line 4, in <module>\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/torchvision/ops/roi_align.py\", line 4, in <module>\n",
      "    from .roi_align import roi_align\n",
      "    from .roi_align import roi_align\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/torchvision/ops/roi_align.py\", line 4, in <module>\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/torchvision/ops/roi_align.py\", line 4, in <module>\n",
      "    import torch._dynamo\n",
      "    import torch._dynamo\n",
      "    import torch._dynamo\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/torch/_dynamo/__init__.py\", line 2, in <module>\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/torch/_dynamo/__init__.py\", line 2, in <module>\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/torch/_dynamo/__init__.py\", line 2, in <module>\n",
      "    import torch._dynamo\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/torch/_dynamo/__init__.py\", line 2, in <module>\n",
      "    from . import allowed_functions, convert_frame, eval_frame, resume_execution\n",
      "    from . import allowed_functions, convert_frame, eval_frame, resume_execution    from . import allowed_functions, convert_frame, eval_frame, resume_execution\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/torch/_dynamo/allowed_functions.py\", line 30, in <module>\n",
      "    from . import allowed_functions, convert_frame, eval_frame, resume_execution\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/torch/_dynamo/allowed_functions.py\", line 30, in <module>\n",
      "\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/torch/_dynamo/allowed_functions.py\", line 30, in <module>\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/torch/_dynamo/allowed_functions.py\", line 30, in <module>\n",
      "    from .utils import hashable, is_safe_constant, NP_SUPPORTED_MODULES\n",
      "    from .utils import hashable, is_safe_constant, NP_SUPPORTED_MODULES\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/torch/_dynamo/utils.py\", line 89, in <module>\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/torch/_dynamo/utils.py\", line 89, in <module>\n",
      "    from .utils import hashable, is_safe_constant, NP_SUPPORTED_MODULES\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/torch/_dynamo/utils.py\", line 89, in <module>\n",
      "    from .utils import hashable, is_safe_constant, NP_SUPPORTED_MODULES\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/torch/_dynamo/utils.py\", line 89, in <module>\n",
      "    import torch.fx.experimental.symbolic_shapes\n",
      "    import torch.fx.experimental.symbolic_shapes\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/torch/fx/experimental/symbolic_shapes.py\", line 38, in <module>\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/torch/fx/experimental/symbolic_shapes.py\", line 38, in <module>\n",
      "    import torch.fx.experimental.symbolic_shapes\n",
      "    import torch.fx.experimental.symbolic_shapes\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/torch/fx/experimental/symbolic_shapes.py\", line 38, in <module>\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/torch/fx/experimental/symbolic_shapes.py\", line 38, in <module>\n",
      "    from torch.utils._sympy.functions import FloorDiv, Mod, IsNonOverlappingAndDenseIndicator\n",
      "        from torch.utils._sympy.functions import FloorDiv, Mod, IsNonOverlappingAndDenseIndicatorfrom torch.utils._sympy.functions import FloorDiv, Mod, IsNonOverlappingAndDenseIndicator\n",
      "\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/torch/utils/_sympy/functions.py\", line 1, in <module>\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/torch/utils/_sympy/functions.py\", line 1, in <module>\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/torch/utils/_sympy/functions.py\", line 1, in <module>\n",
      "    from torch.utils._sympy.functions import FloorDiv, Mod, IsNonOverlappingAndDenseIndicator\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/torch/utils/_sympy/functions.py\", line 1, in <module>\n",
      "        import sympyimport sympy\n",
      "\n",
      "    import sympy\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/sympy/__init__.py\", line 74, in <module>\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/sympy/__init__.py\", line 74, in <module>\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/sympy/__init__.py\", line 74, in <module>\n",
      "    import sympy\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/sympy/__init__.py\", line 74, in <module>\n",
      "    from .polys import (Poly, PurePoly, poly_from_expr, parallel_poly_from_expr,\n",
      "    from .polys import (Poly, PurePoly, poly_from_expr, parallel_poly_from_expr,\n",
      "    from .polys import (Poly, PurePoly, poly_from_expr, parallel_poly_from_expr,\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/sympy/polys/__init__.py\", line 79, in <module>\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/sympy/polys/__init__.py\", line 79, in <module>\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/sympy/polys/__init__.py\", line 79, in <module>\n",
      "    from .polys import (Poly, PurePoly, poly_from_expr, parallel_poly_from_expr,\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/sympy/polys/__init__.py\", line 79, in <module>\n",
      "        from .polyfuncs import (symmetrize, horner, interpolate,from .polyfuncs import (symmetrize, horner, interpolate,\n",
      "\n",
      "    from .polyfuncs import (symmetrize, horner, interpolate,\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/sympy/polys/polyfuncs.py\", line 10, in <module>\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/sympy/polys/polyfuncs.py\", line 10, in <module>\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/sympy/polys/polyfuncs.py\", line 10, in <module>\n",
      "    from .polyfuncs import (symmetrize, horner, interpolate,\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/sympy/polys/polyfuncs.py\", line 10, in <module>\n",
      "    from sympy.polys.specialpolys import (    from sympy.polys.specialpolys import (    from sympy.polys.specialpolys import (\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/sympy/polys/specialpolys.py\", line 298, in <module>\n",
      "    from sympy.polys.specialpolys import (\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/sympy/polys/specialpolys.py\", line 298, in <module>\n",
      "\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/sympy/polys/specialpolys.py\", line 298, in <module>\n",
      "\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/sympy/polys/specialpolys.py\", line 7, in <module>\n",
      "    from sympy.ntheory import nextprime\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/sympy/ntheory/__init__.py\", line 29, in <module>\n",
      "    from sympy.polys.rings import ring\n",
      "    from sympy.polys.rings import ring\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/sympy/polys/rings.py\", line 30, in <module>\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/sympy/polys/rings.py\", line 30, in <module>\n",
      "    from sympy.polys.rings import ring\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/sympy/polys/rings.py\", line 30, in <module>\n",
      "    from .qs import qs\n",
      "  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 936, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1069, in get_code\n",
      "        from sympy.printing.defaults import DefaultPrintingfrom sympy.printing.defaults import DefaultPrinting\n",
      "\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/sympy/printing/__init__.py\", line 3, in <module>\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 729, in _compile_bytecode\n",
      "KeyboardInterrupt\n",
      "    from sympy.printing.defaults import DefaultPrinting\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/sympy/printing/__init__.py\", line 3, in <module>\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/sympy/printing/__init__.py\", line 3, in <module>\n",
      "    from .pretty import pager_print, pretty, pretty_print, pprint, pprint_use_unicode, pprint_try_use_unicode\n",
      "    from .pretty import pager_print, pretty, pretty_print, pprint, pprint_use_unicode, pprint_try_use_unicode\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/sympy/printing/pretty/__init__.py\", line 3, in <module>\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/sympy/printing/pretty/__init__.py\", line 3, in <module>\n",
      "    from .pretty import pager_print, pretty, pretty_print, pprint, pprint_use_unicode, pprint_try_use_unicode\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/sympy/printing/pretty/__init__.py\", line 3, in <module>\n",
      "    from .pretty import (pretty, pretty_print, pprint, pprint_use_unicode,\n",
      "    from .pretty import (pretty, pretty_print, pprint, pprint_use_unicode,\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/sympy/printing/pretty/pretty.py\", line 16, in <module>\n",
      "    from .pretty import (pretty, pretty_print, pprint, pprint_use_unicode,\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/sympy/printing/pretty/pretty.py\", line 20, in <module>\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/sympy/printing/pretty/pretty.py\", line 20, in <module>\n",
      "    from sympy.printing.pretty.stringpict import prettyForm, stringPict    from sympy.printing.str import sstr\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/sympy/printing/str.py\", line 977, in <module>\n",
      "\n",
      "    from sympy.printing.pretty.stringpict import prettyForm, stringPict\n",
      "  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 936, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1026, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1148, in path_stats\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 147, in _path_stat\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/sympy/printing/pretty/stringpict.py\", line 17, in <module>\n",
      "KeyboardInterrupt\n",
      "    from .pretty_symbology import hobj, vobj, xsym, xobj, pretty_use_unicode, line_width, center\n",
      "  File \"<frozen importlib._bootstrap>\", line 1165, in _find_and_load\n",
      "KeyboardInterrupt\n",
      "    @print_function(StrPrinter)\n",
      "     ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/sympy/printing/printer.py\", line 395, in decorator\n",
      "    return cls(f, print_cls)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/sympy/printing/printer.py\", line 363, in __init__\n",
      "    update_wrapper(self, f)\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/functools.py\", line 35, in update_wrapper\n",
      "    def update_wrapper(wrapper,\n",
      "    \n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libc++abi: terminating with uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating with uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating with uncaught exception of type std::__1::system_error: Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/5n/lggt_xf57s78jjmq538wdr6w0000gn/T/ipykernel_69040/1808906383.py\", line 2, in <module>\n",
      "    base_steps, base_acc = train_model_on_continual_learning_tasks(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lorenzleisner/Desktop/CogSci/Master/WI_SE_25/hands-on-neuroai/src/hands_on_neuroai/training/continual_learning.py\", line 118, in train_model_on_continual_learning_tasks\n",
      "    imgs, labels = next(data_iter)\n",
      "                   ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 631, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1329, in _next_data\n",
      "    idx, data = self._get_data()\n",
      "                ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1295, in _get_data\n",
      "    success, data = self._try_get_data()\n",
      "                    ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1133, in _try_get_data\n",
      "    data = self._data_queue.get(timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/multiprocessing/queues.py\", line 113, in get\n",
      "    if not self._poll(timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/multiprocessing/connection.py\", line 440, in _poll\n",
      "    r = wait([self], timeout)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/multiprocessing/connection.py\", line 948, in wait\n",
      "    ready = selector.select(timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "libc++abi: \n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 2168, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1457, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1348, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1195, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1110, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 992, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 804, in lines\n",
      "    return self._sd.lines\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/stack_data/core.py\", line 677, in included_pieces\n",
      "    scope_pieces = self.scope_pieces\n",
      "                   ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/stack_data/core.py\", line 617, in scope_pieces\n",
      "    for piece in self.source.pieces\n",
      "                 ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/stack_data/core.py\", line 101, in pieces\n",
      "    return list(self._clean_pieces())\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/stack_data/core.py\", line 114, in _clean_pieces\n",
      "    pieces = [\n",
      "             ^\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/stack_data/core.py\", line 114, in <listcomp>\n",
      "    pieces = [\n",
      "             ^\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/stack_data/core.py\", line 168, in _raw_split_into_pieces\n",
      "    for inner_start, inner_end in self._raw_split_into_pieces(sub_stmt, *rang):\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/stack_data/core.py\", line 168, in _raw_split_into_pieces\n",
      "    for inner_start, inner_end in self._raw_split_into_pieces(sub_stmt, *rang):\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/stack_data/core.py\", line 168, in _raw_split_into_pieces\n",
      "    for inner_start, inner_end in self._raw_split_into_pieces(sub_stmt, *rang):\n",
      "  [Previous line repeated 4 more times]\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/stack_data/core.py\", line 166, in _raw_split_into_pieces\n",
      "    for rang, group in sorted(group_by_key_func(body, self.line_range).items()):\n",
      "                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/stack_data/utils.py\", line 124, in group_by_key_func\n",
      "    result[key_func(item)].append(item)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/stack_data/core.py\", line 178, in line_range\n",
      "    return line_range(self.asttext(), node)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/stack_data/utils.py\", line 40, in line_range\n",
      "    (start, _), (end, _) = atok.get_text_positions(node, padded=False)\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/asttokens/asttokens.py\", line 418, in get_text_positions\n",
      "    return self._get_text_positions_tokenless(node, padded)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/asttokens/asttokens.py\", line 367, in _get_text_positions_tokenless\n",
      "    end_node = last_stmt(node)\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/asttokens/util.py\", line 400, in last_stmt\n",
      "    child_stmts = [\n",
      "                  ^\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/asttokens/util.py\", line 400, in <listcomp>\n",
      "    child_stmts = [\n",
      "                  ^\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/asttokens/util.py\", line 162, in iter_children_ast\n",
      "    for child in ast.iter_child_nodes(node):\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/ast.py\", line 278, in iter_child_nodes\n",
      "    yield item\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/torch/utils/data/_utils/signal_handling.py\", line 66, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 69913) is killed by signal: Interrupt: 2. \n",
      "terminating with uncaught exception of type std::__1::system_error: Broken pipe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/asyncio/base_events.py\", line 1898, in _run_once\n",
      "    event_list = self._selector.select(timeout)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/selectors.py\", line 566, in select\n",
      "    kev_list = self._selector.control(None, max_ev, timeout)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lorenzleisner/opt/anaconda3/envs/anicog/lib/python3.11/site-packages/torch/utils/data/_utils/signal_handling.py\", line 66, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 69179) is killed by signal: Abort trap: 6. \n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(\"Training baseline model...\")\n",
    "base_steps, base_acc = train_model_on_continual_learning_tasks(\n",
    "    model=baseline,\n",
    "    train_loaders=train_loaders,\n",
    "    test_loaders=test_loaders,\n",
    "    num_tasks=num_tasks,\n",
    "    steps_per_task=steps_per_task,\n",
    "    lr=learning_rate,\n",
    "    eval_interval=eval_interval,\n",
    "    device=device,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nTraining context-aware model...\")\n",
    "ctx_steps, ctx_acc = train_model_on_continual_learning_tasks(\n",
    "    model=context_model,\n",
    "    train_loaders=train_loaders,\n",
    "    test_loaders=test_loaders,\n",
    "    num_tasks=num_tasks,\n",
    "    steps_per_task=steps_per_task,\n",
    "    lr=learning_rate,\n",
    "    eval_interval=eval_interval,\n",
    "    device=device,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de7cf71",
   "metadata": {},
   "source": [
    "## Step 4: Visualize Task-Specific Accuracy\n",
    "\n",
    "Compare how both models maintain accuracy on the first task as they learn new tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbabdd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(base_steps, base_acc, marker='o', label=\"Baseline (no context)\", linewidth=2)\n",
    "plt.plot(ctx_steps, ctx_acc, marker='s', label=f\"Context-Aware ({context_type})\", linewidth=2)\n",
    "plt.xlabel(\"Global Step\", fontsize=12)\n",
    "plt.ylabel(\"Accuracy on Task 0\", fontsize=12)\n",
    "plt.title(f\"{dataset_name.upper()} - {task_transform_type} Tasks - Accuracy Evolution\", fontsize=14)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5d93d3",
   "metadata": {},
   "source": [
    "## Step 5: Collect Hidden Activations\n",
    "\n",
    "Extract hidden layer representations from both models across all tasks for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dea56ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Collecting baseline hidden activations...\")\n",
    "A_baseline, t_baseline = collect_hidden_activations(\n",
    "    model=baseline,\n",
    "    hidden_module=baseline.fc1,\n",
    "    loaders=train_loaders,\n",
    "    num_tasks=num_tasks,\n",
    "    num_samples_per_task=200,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "print(\"Collecting context-aware model hidden activations...\")\n",
    "A_context, t_context = collect_hidden_activations(\n",
    "    model=context_model,\n",
    "    hidden_module=context_model.fc1,\n",
    "    loaders=train_loaders,\n",
    "    num_tasks=num_tasks,\n",
    "    num_samples_per_task=200,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "print(f\"Baseline activations shape: {A_baseline.shape}\")\n",
    "print(f\"Context model activations shape: {A_context.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b917f605",
   "metadata": {},
   "source": [
    "## Step 6: Analyze Baseline Representation Space (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ba28a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "A_baseline_2d = pca.fit_transform(A_baseline)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, num_tasks))\n",
    "for t in range(min(num_tasks, 10)):  # Show up to 10 tasks to avoid color conflicts\n",
    "    mask = (t_baseline == t)\n",
    "    plt.scatter(A_baseline_2d[mask, 0], A_baseline_2d[mask, 1], \n",
    "               s=20, alpha=0.6, label=f\"task {t}\", color=colors[t])\n",
    "\n",
    "plt.xlabel(f\"PC1 ({pca.explained_variance_ratio_[0]:.1%})\", fontsize=11)\n",
    "plt.ylabel(f\"PC2 ({pca.explained_variance_ratio_[1]:.1%})\", fontsize=11)\n",
    "plt.title(f\"Baseline Model - Hidden Layer Representations (PCA)\", fontsize=12)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Explained variance: PC1={pca.explained_variance_ratio_[0]:.3f}, PC2={pca.explained_variance_ratio_[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596eecfd",
   "metadata": {},
   "source": [
    "## Step 7: Analyze Context-Aware Model Representation Space (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270ab547",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca2 = PCA(n_components=2)\n",
    "A_context_2d = pca2.fit_transform(A_context)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, num_tasks))\n",
    "for t in range(min(num_tasks, 10)):  # Show up to 10 tasks to avoid color conflicts\n",
    "    mask = (t_context == t)\n",
    "    plt.scatter(A_context_2d[mask, 0], A_context_2d[mask, 1], \n",
    "               s=20, alpha=0.6, label=f\"task {t}\", color=colors[t])\n",
    "\n",
    "plt.xlabel(f\"PC1 ({pca2.explained_variance_ratio_[0]:.1%})\", fontsize=11)\n",
    "plt.ylabel(f\"PC2 ({pca2.explained_variance_ratio_[1]:.1%})\", fontsize=11)\n",
    "plt.title(f\"Context-Aware Model ({context_type}) - Hidden Layer Representations (PCA)\", fontsize=12)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Explained variance: PC1={pca2.explained_variance_ratio_[0]:.3f}, PC2={pca2.explained_variance_ratio_[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea638844",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "1. **Dataset Agnostic**: Works with any torchvision dataset (MNIST, CIFAR-10, etc.)\n",
    "2. **Task Flexibility**: Supports multiple task transform types (permutation, rotation, class-incremental)\n",
    "3. **Model Comparison**: Compares baseline vs. context-aware models\n",
    "4. **Analysis Tools**: Uses PCA to visualize how task representations evolve in hidden layers\n",
    "\n",
    "### Key Observations:\n",
    "- **Baseline Model**: May show task overlap/interference in latent space\n",
    "- **Context-Aware Model**: Typically shows better task separation in latent space\n",
    "- **Accuracy Curves**: Context-aware models often better maintain performance on task 0 as new tasks are learned\n",
    "\n",
    "### Next Steps:\n",
    "- Experiment with different datasets (e.g., `cifar10`, `fashionmnist`)\n",
    "- Try different context types (`binary`, `complex`, `rotation`)\n",
    "- Vary task transform types to study different continual learning scenarios\n",
    "- Investigate the relationship between representation separability and task performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anicog",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
